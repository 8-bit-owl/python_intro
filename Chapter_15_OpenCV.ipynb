{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15: OpenCV\n",
    "\n",
    "**OpenCV** provides many image processing and computer vision tools.  While written in C++, it provides a fairly extensive Python interface, enabling it to be used as a Python toolbox, see: [https://docs.opencv.org/4.5.3/](https://docs.opencv.org/4.5.3/).  Use OpenCV for the many powerful image operations such as segmentation, calibration, warping, and even applying deep neural networks to images.  Plotting is fairly limited, and more powerful plotting is available in Matplotlib, see  [Chapter 16: Matplotlib](Chapter_16_Matplotlib.ipynb).\n",
    "\n",
    "For installation, see [Chapter 13](Chapter_13_Numpy.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Operations with OpenCV\n",
    "\n",
    "Images are another data type for which Numpy arrays are useful.  We will use OpenCV to read and process an image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "img = cv.imread('.Images/book.png', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have provided the full path from where Python is running to the `book.png` image in this repo.  The `-1` flag reads in raw data without changing the format or number of channels.  You'll need to adjust your path to point to this image from where you are running Python.  Now let's examine the image we just read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see an output `NoneType`, then `img` was not successfully loaded.  You'll need to adjust the path to the image.  If you want to know the path of where Python is currently running use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\DMorris\\\\Repos\\\\teaching\\\\python_intro'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume you have adjusted the path and successfully read in the image, and it is a `numpy.ndarray`.  Let's examine its size and the pixel type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 160, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it is a 3D array; the `.shape` is a tuple with array dimension sizes, in this case: (height, width, nchannels).  The three channels are (blue, green, red), as this is the default format for OpenCV, which differs from the more usual (red, green, blue) format.  The data type is an unsigned 8-bit type (`uint8`) which stores numbers from 0 to 255 inclusive.  We can extract the 3 components of a sample single pixel as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([212, 187, 143], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[22,28,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can drop the trailing colon to get the same output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([212, 187, 143], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[22,28]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three values are the (blue, green, red) values for that pixel.  Review Numpy [indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html) if this isn't clear.\n",
    "\n",
    "Let's say our goal is to find the horizontal image gradient of the grayscale version of this image.  Here are the steps we would take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf = img / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts a floating point array and scales to a range of 0 to 1, which is the usual range for floating point images.  It is best to use floating point rather than unsigned integers because the gradient can be negative or could be larger than the maximum `uint8` value of 255.  Operating in `uint8` will result in gradients being clipped.  Confirming our new data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgf.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, convert the image to grayscale with `cvtColor`, which is a general purpose colorspace transformation utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf_gray = cv.cvtColor(imgf.astype(np.float32), cv.COLOR_BGR2GRAY)  # Convert 3-channel color to single-channel grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do `help(cv.cvtColor)` you will see that `cvtColor` requires floating-bit arrays be 32-bit, while `img` is 64-bit, so we passed in a 32-bit version of `img`.  This grayscale image is the same size, except with a single channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 160)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgf_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's apply a Sobel operator to obtain the image gradient in x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf_grad_x = cv.Sobel(imgf_gray, cv.CV_32F, 1, 0, ksize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the meaning of the parameters, use: `help(cv.Sobel)`.  Next, let's see how to plot our result.\n",
    "\n",
    "## Plotting with OpenCV\n",
    "OpenCV has some graphical display functions including showing images.  For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('Image',img)\n",
    "cv.waitKey(1)           # This gives OpenCV 1 millisecond to render the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show an image in a **separate window** that should look like this:\n",
    "\n",
    "![Image](.Images/show_book.png)\n",
    "\n",
    "Find the window (which might be underneath this document window) and when you are done, delete it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to draw a circle at the image center.  Using the OpenCV `circle` function, this will actually change the pixel values, so if we want to avoid changing our `img` variable we could make a copy of it just for plotting as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cp = img.copy()\n",
    "img_cen_xy = (img_cp.shape[1]//2, img_cp.shape[0]//2)  # Integer division and order (x,y) \n",
    "cv.circle( img_cp, img_cen_xy, radius=15, color=(0,0,255), thickness=2 )\n",
    "cv.imwrite('.Images/book_circle.png',img_cp)\n",
    "cv.imshow('Image with Circle', img_cp)\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, find this window to see the output which should look like this:\n",
    "\n",
    "![Image](.Images/book_circle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the pixelation as the circle is part of the image.  When done, delete the window with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected Components\n",
    "The OpenCV function: `connectedComponentsWithStats` is quite useful.  You can find detailed information on its arguments using `help(cv.connectedComponentsWithStats)`.  Also below is an example of its use.  First define an 8-bit image with binary components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nimg = ( np.array([1,1,0,1,1,1])[:,None] * np.array([1,1,0,1,1,1,1,1]) ).astype(np.uint8)\n",
    "nimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find connected components and details for each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with each pixel assigned a label value:\n",
      "[[1 1 0 2 2 2 2 2]\n",
      " [1 1 0 2 2 2 2 2]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [3 3 0 4 4 4 4 4]\n",
      " [3 3 0 4 4 4 4 4]\n",
      " [3 3 0 4 4 4 4 4]]\n",
      "Label, Bounding Box,  Npix,  Centroid\n",
      "  0      [0 0 8 6]     13    [ 2.923  2.231]\n",
      "  1      [0 0 2 2]      4    [ 0.500  0.500]\n",
      "  2      [3 0 5 2]     10    [ 5.000  0.500]\n",
      "  3      [0 3 2 3]      6    [ 0.500  4.000]\n",
      "  4      [3 3 5 3]     15    [ 5.000  4.000]\n",
      "Bounding box format: [left,top,width,height]\n"
     ]
    }
   ],
   "source": [
    "cc = cv.connectedComponentsWithStats( nimg )\n",
    "print('Image with each pixel assigned a label value:')\n",
    "print(cc[1])\n",
    "print('Label, Bounding Box,  Npix,  Centroid')\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "for i in range(cc[0]): # cc[0] is the number of connected components\n",
    "    print(f'{i:3}      {cc[2][i,:4]}   {cc[2][i,4]:4}    {cc[3][i,:]}')\n",
    "print('Bounding box format: [left,top,width,height]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the components of the output `cc` are:\n",
    "```\n",
    "cc[0]:  1x1: Number of connected components: N\n",
    "cc[1]:  Input image size with each pixel given its connected component label\n",
    "cc[2]:  Nx5: Bounding box and number of pixels in each component\n",
    "cc[3]:  Nx2: Centroid for each component\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### [Outline](README.md), Next: [Chapter 16: Matplotlib](Chapter_16_Matplotlib.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cv4': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dacb7d2f7fff4c8c051172debf986d5a93c53a46f2df21f8e79bb640e001617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
